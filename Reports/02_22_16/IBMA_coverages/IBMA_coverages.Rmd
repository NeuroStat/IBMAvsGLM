---
title: "IBMA - GLM at 3 stages"
author: "Han Bossier"
date: "22 februari 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

## Introduction
In this report, I will simulate data to execute an image-based meta-analysis by applying a thrid level GLM on top of the standard two levels in individual fMRI data analyses. This is executed using FSL's FLAME1, which is a mixed effects analysis.
  
After obtaining t-maps, we will construct a t confidence interval and look at the emperical coverage of the true value in this interval. 
This first part quickly describes the 3 stage GLM procedure using a mixed effects approach.

#### Mathematical definition
##### Level 1
At each stage, we calculate the COPE and VARCOPES which are being sent to the next level in the GLM. \
The 3 level GLM starts at the first level by relating the design of the experiment to the observed time series for each individual. For a given voxel and each subject *k*, we have:

$$ Y_k = X_k\beta_k+\epsilon_k  $$

With $Y_k$ the $T \times 1$ observed BOLD time series at that voxel, $X_k$ the $T \times p$ design matrix (containing *p* regressors), $\beta_k$ a $p \times 1$ vector of parameters and finally $\epsilon_k$ the $T \times 1$ error term. 
The first level COPE map is estimated by:

$$ c\hat{\beta}_k=c(X'_kX_k)^{-1}X'_kY_k $$

Here we assume assume no autocorrelation in the time series. The VARCOPE map is calculated by:

$$ \hat{Var}(c\hat{\beta}_k) = (X'_kX_k)^{-1}c'\hat{\sigma}^2_k $$
With:
$$ \hat{\sigma}^2_k = (Y - X\hat{\beta}_k)'(Y - X\hat{\beta}_k)/(T - p) $$

##### Level 2
The second level GLM, we apply a group model:

$$ Y_G = X_G\beta_G+\epsilon^{*}_G $$
With $X_G$ the $N \times p_G$ group-level design matrix, $\beta_G$ the group level parameter vector and $\epsilon^{*}_G$ the imperfect estimated group error (due to using first level contrasts) vector in which $Var(\epsilon_G)$ contains both intrasubject as well as between-subject variance. The group level parameters are estimated through:

$$ \hat{\beta_G} = X^{-}_GY_G $$ In which $^{-}$ denotes the pseudo-inverse. \
The GLS approach which is used in FSL's FLAME1 mixed effects approach assumes that:
$$ Var(\epsilon^{*}_G) = \sigma^2I_N + Var_{\beta}(Y_G) $$ 

In which the $\beta$ subscript denotes this being intrasubject variance. The estimates of these variances are used from the first level. The $\sigma^2_G$ is estimated through an iterative estimation algorithm (pressumable REML).

##### Level 3
Finally, the third level repeats the second level with the object of interest now being studies instead of subjects. Hence, we apply a study model:

$$ Y_S = X_S\beta_S+\epsilon^{**}_S $$

> Question: don't we need to incorporate imperfect estimations from the second level in the third level?

My question now is if $Var(\epsilon^{**}_S)$ comes down to:

$$ Var(\epsilon^{**}_S) = \sigma^2I_K + Var_{\beta_G}(Y_S) + Var_{\beta}(Y_G) $$

In which $Var_{\beta_G}(Y_S)$ denotes between-subject variability and $\sigma^2I_K$ between-study (over $K$ studies) variability. 


## Simulation
We simulate fMRI time series on a grid of 2 x 2 x 2 voxels. The fMRI analysis consists of one blocked design condition (20 sec ON/OFF) with a TR of 2 sec and a total of 200 scans. We consider increasing the sample size within studies from 10 to 100 in steps of 10 combined with either 2, 5 or 10 studies at the third level. We start with 3000 simulations.

### Data generation.
Data is being generated in R using neuRosim (code is being simplified):

```{r eval=FALSE}
TR <- 2
nscan <- 200
total <- TR*nscan
on1 <- seq(1,total,40)
onsets <- list(on1)
duration <- list(20)
effect.null <- list(0)                              ## No effect
effect <- list(1) 			                            ## Effect of 1 for creating designmatrix
DIM <- c(2,2,2)

####************####
#### Design matrices
####************####
# Design Matrices via neuRosim:
#     * We need two design vectors:
#      * The first one will be the column of the design matrix in the analysis.
#      * The second one is used to generate data with a NULL effect.
design.Cond1 <- simprepTemporal(onsets = list(on1), durations = list(duration[[1]]),
                       hrf = "double-gamma", TR = TR, totaltime = total,
                       effectsize = list(effect[[1]]))

design.null <- simprepTemporal(regions = 1, onsets = onsets, durations = duration,
                       hrf = "double-gamma", TR = TR, totaltime = total,
                       effectsize = effect.null)

# X-matrix in order to fit the model later on.
x <- matrix(c(simTSfmri(design.Cond1, nscan=nscan, TR=TR, noise="none")),ncol=1)

####************####
#### GENERATE DATA
####************####
# For loop over studies
for(t in 1:nstud){
  # For loop over nsub
  for(s in 1:nsub){
    # Define the regions (which does nothing as there is no effect, )
    regions <- simprepSpatial(regions = 1, coord = c(4,4,4), radius = list(1), form ="cube", fading = 0)

    # Weighting structure.
    #   * Order = white, temporal, low-frequency, physyiological, task related and spatial.
    w <- c(1,0,0,0,0,0)

    # Base value
    base <- 5

    # Actual simulated data
    sim.data <- simVOLfmri(design=design.null, image=regions, base=base, dim=DIM, SNR=0.5,
                 type ="gaussian", noise= "mixture", spat="gaussRF", FWHM=2, weights=w, verbose = TRUE)
      # Transform it to correct dimension (Y = t x V)
      Y.data <- t(matrix(sim.data,ncol=nscan))

#[...] continue with for loop below
```

The first level GLM is done as follow:
```{r eval=FALSE}
    ####************####
    #### ANALYZE DATA: 1e level GLM
    ####************####

    # Fitting GLM model.
    model.lm <- lm(Y.data ~ x)
    b1 <- coef(model.lm)['x',]
    COPE[,s] <- b1

      # Estimate residual (we need to extend the design matrix with an intercept)
      xIN <- cbind(1,x)
      BETA <- coef(model.lm)
      res <- (t(Y.data - xIN %*% BETA) %*% (Y.data - xIN %*% BETA))/nscan - 2
      res <- diag(res)
      # Contrast: not interested in intercept
      CONTRAST <- matrix(c(0,1),nrow=1)
    # Calculate varcope
    VARCOPE[,s] <- CONTRAST %*% (solve(t(xIN) %*% xIN )) %*% t(CONTRAST) %*% res
  } # END of subject part in FOR loop
#[...] continue with for loop below
```

For the second level of the GLM, we will use FSL from within R. We need to write some auxiliarly files which FSL will use. We can skip that code (though shown below):

```{r eval=FALSE}
  ####************####
  #### GROUP ANALYSIS: 2e level using FLAME
  ####************####

  # Write auxiliarly files to DataWrite. We need:
    # GRCOPE in nifti
    # GRVARCOPE in nifti
    # 4D mask
    # design.mat file
    # design.grp file
    # design.con file

    #----- 1 ----#
    ### Design.mat
    fileCon <- paste(DataWrite,"/design.mat",sep="")
    # Text to be written to the file
    cat('/NumWaves\t1
    /NumPoints\t',paste(nsub,sep=''),'
    /PPheights\t\t1.000000e+00

    /Matrix
    ',rep("1.000000e+00\n",nsub),file=fileCon)

    #----- 2 ----#
    ### Design.con
    fileCon <- file(paste(DataWrite,"/design.con", sep=""))
    	writeLines('/ContrastName1	Group Average
    /NumWaves	1
    /NumContrasts	1
    /PPheights		1.000000e+00
    /RequiredEffect		5.034

    /Matrix
    1.000000e+00
    ',fileCon)
    close(fileCon)

      #----- 3 ----#
      ### Design.grp
    fileCon <- paste(DataWrite,"/design.grp",sep="")
    # Text to be written to the file
    cat('/NumWaves\t1
    /NumPoints\t',paste(nsub,sep=''),'

    /Matrix
    ',rep("1\n",nsub),file=fileCon)

    #----- 4 ----#
    ### COPE.nii
    GRCOPE4D <- nifti(img=array(COPE,dim=c(DIM,nsub)),dim=c(DIM,nsub),datatype = 16)
    writeNIfTI(GRCOPE4D, filename = paste(DataWrite,'/GRCOPE',sep=''),gzipped=FALSE)

    #----- 5 ----#
    ### VARCOPE.nii
    GRVARCOPE4D <- nifti(img=array(VARCOPE,dim=c(DIM,nsub)),dim=c(DIM,nsub),datatype = 16)
    writeNIfTI(GRVARCOPE4D, filename = paste(DataWrite,'/GRVARCOPE',sep=''),gzipped=FALSE)

    #----- 6 ----#
    ### mask.nii
    mask <- nifti(img=array(1, dim=c(DIM,nsub)), dim=c(DIM,nsub), datatype=2)
    writeNIfTI(mask, filename = paste(DataWrite,'/mask',sep=''),gzipped=FALSE)

    # FSL TIME!
    setwd(DataWrite)
    command <- paste(fslpath, 'flameo --cope=GRCOPE --vc=GRVARCOPE --mask=mask --ld=study',t,'_stats --dm=design.mat --cs=design.grp --tc=design.con --runmode=flame1', sep='')
    Sys.setenv(FSLOUTPUTTYPE="NIFTI")
    system(command)

    # Put the result of pooling subjects in a vector for the COPE and VARCOPE
    STCOPE[,t] <- readNIfTI(paste(DataWrite,"/study",t,"_stats/cope1.nii",sep=""), verbose=FALSE, warn=-1, reorient=TRUE, call=NULL)[,,]
    STVARCOPE[,t] <- readNIfTI(paste(DataWrite,"/study",t,"_stats/varcope1.nii",sep=""), verbose=FALSE, warn=-1, reorient=TRUE, call=NULL)[,,]
} # End of study part in FOR loop
```
 
Now we have the third level GLM in which we again use FSL.

```{r eval=FALSE}
####************####
#### META-ANALYSIS: 3e level using FLAME
####************####
# Write auxiliarly files to DataWrite. We need:
  # STCOPE in nifti
  # STVARCOPE in nifti
  # 4D mask
  # design.mat file
  # design.grp file
  # design.con file

  #----- 1 ----#
  ### Design.mat
  fileCon <- paste(DataWrite,"/STdesign.mat",sep="")
  # Text to be written to the file
  cat('/NumWaves\t1
  /NumPoints\t',paste(nstud,sep=''),'
  /PPheights\t\t1.000000e+00

  /Matrix
  ',rep("1.000000e+00\n",nstud),file=fileCon)

  #----- 2 ----#
  ### Design.con
  fileCon <- file(paste(DataWrite,"/STdesign.con", sep=""))
  	writeLines('/ContrastName1	Group Average
  /NumWaves	1
  /NumContrasts	1
  /PPheights		1.000000e+00
  /RequiredEffect		5.034

  /Matrix
  1.000000e+00
  ',fileCon)
  close(fileCon)

  #----- 3 ----#
  ### Design.grp
  fileCon <- paste(DataWrite,"/STdesign.grp",sep="")
  # Text to be written to the file
  cat('/NumWaves\t1
  /NumPoints\t',paste(nstud,sep=''),'

  /Matrix
  ',rep("1\n",nstud),file=fileCon)

  #----- 4 ----#
  ### STCOPE.nii
  STCOPE4D <- nifti(img=array(STCOPE,dim=c(DIM,nstud)),dim=c(DIM,nstud),datatype = 16)
  writeNIfTI(STCOPE4D, filename = paste(DataWrite,'/STCOPE',sep=''),gzipped=FALSE)

  #----- 5 ----#
  ### VARCOPE.nii
  STVARCOPE4D <- nifti(img=array(STVARCOPE,dim=c(DIM,nstud)),dim=c(DIM,nstud),datatype = 16)
  writeNIfTI(STVARCOPE4D, filename = paste(DataWrite,'/STVARCOPE',sep=''),gzipped=FALSE)

  #----- 6 ----#
  ### mask.nii
  mask <- nifti(img=array(1, dim=c(DIM,nstud)), dim=c(DIM,nstud), datatype=2)
  writeNIfTI(mask, filename = paste(DataWrite,'/mask',sep=''),gzipped=FALSE)

# FSL TIME!
setwd(DataWrite)
command <- paste(fslpath, 'flameo --cope=STCOPE --vc=STVARCOPE --mask=mask --ld=MA_stats --dm=STdesign.mat --cs=STdesign.grp --tc=STdesign.con --runmode=flame1', sep='')
Sys.setenv(FSLOUTPUTTYPE="NIFTI")
system(command)
```


Now we want to construct a confidence interval around the COPE-map through:

```{r eval=FALSE}
COPE <- matrix(readNIfTI(paste(DataWrite,"/MA_stats/cope1.nii",sep=""), verbose=FALSE, warn=-1, reorient=TRUE, call=NULL)[,,],ncol=1)
SE <- sqrt(matrix(readNIfTI(paste(DataWrite,"/MA_stats/varcope1.nii",sep=""), verbose=FALSE, warn=-1, reorient=TRUE, call=NULL)[,,],ncol=1))
  # Degrees of freedom (corresponds to number of studies - 1)
  tdof_t1 <- readNIfTI(paste(DataWrite,"/MA_stats/tdof_t1.nii",sep=""), verbose=FALSE, warn=-1, reorient=TRUE, call=NULL)[1,1,1]

CI.upper.t <- COPE +  (qt(0.975,df=tdof_t1) * SE)
CI.lower.t <- COPE -  (qt(0.975,df=tdof_t1) * SE)
```



## Results
First, we can look at the distribution of the T-values at the third level over all 8 voxels AND all simulations. We focus on the scenario in which we have 100 subjects, divided in 30 studies. 

```{r echo=FALSE, cache=TRUE}
rm(list=ls())
# Set starting seed
set.seed(11121990)
# Directories of the data for different takes
DATAwd <- list(
	'Take[1]' = "/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take1",
	'Take[2]' = "/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take2",
  'Take[3]' = "/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take3",
	'Take[4]' = "/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take4/Results",
	'Take[5]' = "/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take5",
  'Take[6]' = "/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take6",
	'Take[7]' = "/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/IBMA"
	)
# Prefixes
prefix <- list(
	'Take[1]' = "WNSm",
	'Take[2]' = "UNI_",
  'Take[3]' = 'SK_',
	'Take[4]' = "UNI_SK_",
	'Take[5]' = 'SK_',
  'Take[6]' = 'SD_',
	'Take[7]' = 'IBMA_'
)
NUMDATAwd <- length(DATAwd)
currentWD <- 7
# Number of scenarios
NumScen.tmp <- matrix(c(
                1,7,
                2,1,
                3,45,
                4,45,
                5,45,
                6,30,
								7,30
              ), ncol=2, byrow=TRUE)
NumScen <- NumScen.tmp[currentWD,2]
# Number of conficence intervals
PossibleCIs <- c('norm','t','weightVar')
CIs.tmp <- list(
			'1' = c(1,2,3),
			'2' = c(1,2,3),
			'3' = c(1,2,3),
			'4' = c(1,2,3),
			'5' = c(1,2,3),
			'6' = c(1,2,3),
			'7' = c(2)
			)
CIs <- PossibleCIs[c(CIs.tmp[[currentWD]])]
NumCI <- length(CIs)
# Which type of objects are to be loaded in?
ObjType.tmp <- list(
	'1' = c('CIs','WeightedAvg'),
	'2' = c('CIs','WeightedAvg'),
	'3' = c('CIs','WeightedAvg'),
	'4' = c('CIs','WeightedAvg'),
	'5' = c('CIs','WeightedAvg'),
	'6' = c('CIs','WeightedAvg'),
	'7' = c('CIs')
	)
ObjType <- ObjType.tmp[currentWD]
# Number of objects to be loaded in:
	# * Scenario 1-6: CIs + the weighted average
	# * Scenario 7: only t CI
		# * Second column is for initilizing vectors, third for effective loading in objects
NumObjects.tmp <- matrix(c(
	1, NumCI*2 + 1,
	2, NumCI*2 + 1,
	3, NumCI*2 + 1,
	4, NumCI*2 + 1,
	5, NumCI*2 + 1,
	6, NumCI*2 + 1,
	7, NumCI * 2
	),ncol=2,byrow=TRUE)
NumEffObj <- NumObjects.tmp[currentWD,2]
# Number of executed simulations
nsim.tmp <- matrix(c(
                1,4176,
                2,3000,
                3,350,
                4,1500,
                5,500,
                6,3000,
								7,2500
              ), ncol=2, byrow=TRUE)
nsim <- nsim.tmp[currentWD,2]
# Dimension of brain
DIM.tmp <- array(NA, dim=c(NUMDATAwd,3))
	DIM.tmp[c(1,3,5),] <- c(16,16,16)
	DIM.tmp[c(2,4),] <- c(1,1,1)
	DIM.tmp[c(6,7),] <- c(2,2,2)
DIM <- DIM.tmp[currentWD,]
# Number of subjects and studies
TablesOverview <- list(
	'[1]' = '/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take3/OverView.Sel.txt',
	'[2]' = '/Volumes/2_TB_WD_Elements_10B8_Han/PhD/Simulation/Results/Take6/OverView.txt'
	)
overview.tmp <- matrix(c(			# This takes the element from TablesOverview
                1,NA,
                2,NA,
                3,1,
                4,1,
                5,1,
                6,2,
								7,2,
								8,2
              ), ncol=2, byrow=TRUE)
OverView.Sel <- read.table(file=TablesOverview[[overview.tmp[currentWD,2]]], header=TRUE)
# Load in libraries
library(AnalyzeFMRI)
library(fmri)
library(lattice)
library(gridExtra)
library(oro.nifti)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
library(Hmisc)
library(devtools)
library(neuRosim)
library(scatterplot3d)
# Function for data wrangling: indicator for CI and true value
indicating <- function(UPPER, LOWER, trueVal){
	IND <- trueVal >= LOWER & trueVal <= UPPER
	COVERAGE <- apply(IND, 1, mean, na.rm=TRUE)
	return(COVERAGE)
}
# Load in functions from FixRan study
source('~/Dropbox/PhD/PhDWork/Meta\ Analysis/R\ Code/Studie_FixRan/FixRanStudyGit.git/Development/functions.R')
##
###############
### Data Wrangling
###############
##
###############
# Data has been pre-processed in the PreProcessExtended.R file. All simulations are there being read in and combined.
	# Structue: each scenario = a list
		# Each list: rows = voxels, columns = simulations
# Load in these objects
OBJECTS <- c('CI.upper.t.All', 'CI.lower.t.All')
	NumObjects <- length(OBJECTS)
for(i in 1:NumObjects){
	load(paste(DATAwd[[currentWD]], '/Take',currentWD,'-',OBJECTS[i],sep=''))
}
# True value
trueVal <- 0
# CI coverages over all voxels and simulations
mean.coverage.t <- array(NA,dim=c(prod(DIM),NumScen))
# For loop over all scenarios
for(s in 1:NumScen){
	mean.coverage.t[,s] <- indicating(UPPER = CI.upper.t.All[[s]], LOWER = CI.lower.t.All[[s]], trueVal = trueVal)
}
# Put the 3 CI coverages in a list
mean.coverages <- list('t' = mean.coverage.t)
CI.coverages <- data.frame(
	'Mean' = matrix(sapply(mean.coverages, FUN=function(...){apply(...,2,mean)}),ncol=1),
	'SD' = matrix(sapply(mean.coverages, FUN=function(...){apply(...,2,sd)}),ncol=1),
	'Scenario' = rep(seq(1,NumScen),NumCI),
	'CI' = rep(CIs, each = NumScen),
	'SampleSize' = rep(OverView.Sel[,'Subjects'],NumCI),
	'Studies' = rep(OverView.Sel[,'Studies'],NumCI)
	)
CI.coverages$CI <- factor(CI.coverages$CI, labels=CIs)
	if(!currentWD %in% c(1,2)){
		CI.coverages$SampleSize <- factor(CI.coverages$SampleSize)
		CI.coverages$Studies <- factor(CI.coverages$Studies)
	}
##############################################
# T statistic images from 3e level: last scenario
S30TVal.lvl3 <- array(NA,dim=c(prod(DIM),2827))
# For loop
for(i in 1:nsim){
	values <- try(readNIfTI(paste(DATAwd[[currentWD]],'/',i,'/','SCEN_30/MA_stats/tstat1.nii',sep=''), verbose=FALSE, warn=-1, reorient=TRUE, call=NULL)[,,],silent=TRUE)
	if(class(values)=='try-error')next
	S30TVal.lvl3[,i] <- values
}
```


```{r echo=FALSE, fig.align='center', fig.width=5}
library(ggplot2)
hist(S30TVal.lvl3, main='T-values (third level) when N = 100 and K = 10', xlab='T-value')
```

Now we look at the coverage:
```{r echo=FALSE, fig.align='center', fig.width=5}
# Plotting the coverages
colours <- c('#1b9e77','#d95f02','#7570b3')
ggplot(CI.coverages, aes(x=SampleSize, y=Mean, colour=Studies)) +
  geom_point(aes(colour=Studies),size=1.3) +
  geom_line(aes(group=Studies), size=1) +
	geom_hline(yintercept=0.95,colour='red') +
  scale_x_discrete(name="Sample Size") +
  scale_colour_manual(values = colours, name='Amount of studies', labels = c(2,5,10)) +
  ggtitle(label='Coverages of CI over all voxels and simulations') +
  theme(plot.title = element_text(lineheight=.4,size=13, face="plain"),
    axis.text.x = element_text(angle = 315, hjust = 0, vjust = 0.95),
		legend.key = element_rect(fill='#d9d9d9', colour = '#d9d9d9'),
		legend.background = element_rect(colour = '#d9d9d9', fill = '#d9d9d9'),
		strip.background = element_rect(fill='#d9d9d9'),
		legend.position="top")
```



 